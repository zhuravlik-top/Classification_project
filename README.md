
Цель проекта: Предсказать, будет ли завтра дождь в различных регионах Австралии.

# 1.EDA

## Целевая переменная (таргет):

RainTomorrow - бинарная категориальная переменная:

"No" (0) - дождя не будет

"Yes" (1) - будет дождь

## Исходные признаки:

Датасет содержит 23 признака, включая:

### Метеорологические данные:
MinTemp, MaxTemp, Rainfall, Evaporation, Sunshine, WindGustDir, WindGustSpeed, WindDir9am, WindDir3pm, WindSpeed9am, WindSpeed3pm, Humidity9am, Humidity3pm, Pressure9am, Pressure3pm, Cloud9am, Cloud3pm, Temp9am, Temp3pm

### Категориальные признаки: 
Location, WindGustDir, WindDir9am, WindDir3pm, RainToday

### Временные признаки: 
Date

## Анализ данных и обнаруженные проблемы:

Обнаружены значительные пропуски в нескольких признаках

Evaporation (62,790), Sunshine (69,835), Cloud9am (55,888), Cloud3pm (59,358) - более 40% пропусков

Решение: Удалены столбцы с большим количеством пропусков, так как они не несут значимой информации

### Обработка целевой переменной:

Удалены строки с пропущенными значениями в RainTomorrow (3,267 записей)

### Преобразование даты:

Разбита на отдельные числовые признаки: Year, Month, Day

### Распределение признаков:

Большинство числовых признаков имеют нормальное распределение

Humidity9am имеет левостороннее смещение

Rainfall имеет ненормальное распределение с экстремальными значениями

### Категориальные признаки:

Обработаны пропуски заменой на строку 'missing'

RainToday преобразован в числовой формат (0/1/-1)

### Корреляционный анализ:

Обнаружена сильная корреляция между одинаковыми признаками в разное время суток

Локация сильно коррелирует с большинством метеорологических признаков

## Предобработка данных:
Создан пайплайн предобработки:

Числовые признаки: Замена пропусков средним значением (SimpleImputer)

Категориальные признаки: Target Encoding для Location, WindGustDir, WindDir9am, WindDir3pm

Разделение данных: 80/20 с стратификацией по целевой переменной

Распределение классов:

Класс 0 (No rain): 88,252 примеров (77.6%)

Класс 1 (Rain): 25,502 примеров (22.4%)

Наблюдение: Наличие дисбаланса классов

## Результаты EDA:
Все признаки преобразованы в числовой формат

Пропуски заполнены

Данные успешно разделены на train/test выборки

Созданы и сохранены предобработанные datasets для дальнейшего моделирования

# 2.BASELINE

Методология тестирования

Для построения baseline были протестированы 5 различных алгоритмов машинного обучения с использованием предобработанных данных. Все модели обучались на одном наборе признаков, полученном после применения функции EDA_preprocess(), которая включает:

Заполнение пропусков в числовых признаках средними значениями

Target encoding для категориальных признаков

Стратифицированное разделение на train/test (80/20)

## Детальные результаты моделей
### 1. Dummy Classifier (Бейзлайн)
Стратегия: most_frequent - всегда предсказывает наиболее частый класс

Accuracy: 0.7758 - соответствует доле majority класса в данных

Precision/Recall/F1: 0.0000 - модель не предсказывает положительный класс

ROC-AUC: 0.5000 - случайное угадывание

### 2. Logistic Regression
Accuracy: 0.8397 (+6.4% к бейзлайну)

Precision: 0.7263 - хорошее качество положительных прогнозов

Recall: 0.4569 - низкое покрытие фактических дождей

F1-Score: 0.5609 - баланс между precision и recall

ROC-AUC: 0.8508 - хорошая разделяющая способность

Проблема: модель не сошлась (ConvergenceWarning)

### 3. Decision Tree Classifier
Параметры: max_depth=10 для предотвращения переобучения

Accuracy: 0.8377

Precision: 0.6982

Recall: 0.4860 - лучший среди линейных моделей

F1-Score: 0.5731

ROC-AUC: 0.8409

### 4. Random Forest Classifier 
Accuracy: 0.8569 - лучший результат

Precision: 0.7745 - лучший результат

Recall: 0.5098

F1-Score: 0.6149 - лучший результат

ROC-AUC: 0.8850 - лучший результат

### 5. Gradient Boosting Classifier
Accuracy: 0.8498

Precision: 0.7511

Recall: 0.4936

F1-Score: 0.5957

ROC-AUC: 0.8692

# Общие закономерности:

Humidity3pm доминирует во всех моделях как самый важный признак

Метеорологические показатели (Rainfall, WindGustSpeed, Pressure3pm) стабильно в топ-5

Локация имеет среднюю важность благодаря Target Encoding

Временные признаки (Year, Month, Day) имеют низкую важность

Сравнение между моделями:
Decision Tree:

Сильная концентрация важности: Humidity3pm = 56.2%

Более простая интерпретация признаков

Random Forest:

Более сбалансированное распределение важности

Humidity3pm = 19.0%, другие признаки имеют сравнимый вес

Учитывает больше взаимодействий между признаками

Gradient Boosting:

Экстремальная важность Humidity3pm = 64.5%

Сильная зависимость от ключевых признаков

Ключевые выводы
Random Forest показал наилучшие результаты по всем метрикам и выбран как лучшая baseline модель

Проблема дисбаланса классов явно проявляется в низких значениях Recall (45-51%), что означает:

Модели пропускают около 50% фактических случаев дождя

# 3. IMPROVEMENTS
### Эксперименты по улучшению модели

Было проведено несколько экспериментов по улучшению качества моделей:

### 1. Преобразования распределения признаков
**Действия**: Применены логарифмические преобразования (np.log1p) для признаков с ненормальным распределением:
- `Rainfall_Log` - логарифмированный Rainfall
- `WindSpeed9am_Log` - логарифмированный WindSpeed9am  
- `Humidity9am_square` - квадратичное преобразование Humidity9am

**Результат**: Незначительные изменения метрик (±0.002), существенных улучшений не выявлено

**Объяснение**: Исходные признаки уже содержали достаточную информацию для моделей, преобразования распределения не добавили значимой предсказательной силы

### 2. Feature Engineering - разностные признаки
**Действия**: Созданы признаки, отражающие изменения метеопараметров в течение дня:
- `Temp_diff` (разница температур между 15:00 и 9:00)
- `Humidity_diff` (разница влажности)
- `Pressure_diff` (разница давления) 
- `Wind_diff` (разница скорости ветра)
- `Max_Min_Temp_diff` (разница максимальной и минимальной температуры)

**Результат**:
- **GradientBoosting**: +0.0012 accuracy, +0.0025 F1, +0.0042 ROC-AUC
- **LogisticRegression**: незначительное улучшение
- **RandomForest**: стабильные результаты

**Объяснение**: Разностные признаки добавили ценную информацию о динамике погодных условий, что особенно помогло GradientBoosting лучше улавливать сложные зависимости

### 3. Временные признаки (скользящее среднее)
**Действия**: Добавлены признаки, отражающие средние значения за предыдущие 3 дня для ключевых параметров

**Результат**: Резкое ухудшение всех метрик (F1 упал на 0.28-0.32)

**Объяснение**: Временные зависимости не улучшили прогноз, возможно из-за особенностей данных или недостаточной длины временных рядов

### 4. Борьба с дисбалансом классов

#### SMOTE (Synthetic Minority Over-sampling Technique)
**Результат**:
- Увеличился Recall (+0.028-0.066)
- Снизился Precision (-0.031-0.081) 
- **RandomForest**: F1-score улучшился на +0.011
- **GradientBoosting**: F1-score улучшился на +0.004

#### Class Weight Balancing
**Результат**: Аналогично SMOTE - улучшение Recall за счет Precision

**Вывод**: Оба метода помогают лучше обнаруживать случаи дождя, но снижают точность прогнозов

### 5. Комбинированный подход (Diff + SMOTE)
**Результат**: Наилучший баланс метрик для RandomForest:
- **F1**: +0.014 по сравнению с baseline
- **Recall**: +0.034
- **ROC-AUC**: +0.0007

## Тюнинг гиперпараметров

### Метод тюнинга
- **Алгоритм**: `RandomizedSearchCV`
- **Количество итераций**: 10
- **Кросс-валидация**: 5 фолдов
- **Метрика оптимизации**: F1-score
- **Модель**: RandomForestClassifier с SMOTE и разностными признаками

### Сетка гиперпараметров

param_grid = {
    "model__n_estimators": [50, 100, 200, 500],
    "model__max_depth": [None, 10, 20, 30], 
    "model__min_samples_split": [2, 5, 10]
} Оптимальные значения
n_estimators: 500

max_depth: 10

min_samples_split: 5

Best F1-score: 0.7932

Прирост качества
После тюнинга гиперпараметров достигнуто улучшение F1-score до 0.7932, что представляет значительный прирост по сравнению с baseline моделями.

### Итоговые выводы

Наиболее эффективные улучшения:

Разностные признаки (Feature Engineering)

Комбинация SMOTE с тюнингом гиперпараметров

Лучшая конфигурация: RandomForest с разностными признаками, SMOTE и оптимизированными гиперпараметрами

Ключевое достижение: Увеличение F1-score с 0.7615 (baseline) до 0.7932 (финальная модель) - прирост +0.0317

